<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/Verifica_cacamba/config.json">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Verifica_cacamba/config.json" />
              <option name="updatedContent" value="{&#10;  &quot;camera&quot;: {&#10;    &quot;resolucao_largura&quot;: 640,&#10;    &quot;resolucao_altura&quot;: 480,&#10;    &quot;fps&quot;: 30,&#10;    &quot;clip_min&quot;: 0.1,&#10;    &quot;clip_max&quot;: 2.0,&#10;    &quot;laser_potencia&quot;: 360&#10;  },&#10;  &quot;medicoes&quot;: {&#10;    &quot;altura_camera_chao&quot;: 0.725,&#10;    &quot;altura_caixa&quot;: 0.20,&#10;    &quot;profundidade_min_caixa&quot;: 0.45,&#10;    &quot;profundidade_max_caixa&quot;: 0.85,&#10;    &quot;area_minima_pixels&quot;: 5000&#10;  },&#10;  &quot;protecao_pessoa&quot;: {&#10;    &quot;profundidade_minima_corpo&quot;: 0.20,&#10;    &quot;area_maxima_corpo&quot;: 200000,&#10;    &quot;velocidade_max_mudanca&quot;: 0.05,&#10;    &quot;tempo_minimo_entre_mudancas&quot;: 1.0&#10;  },&#10;  &quot;roi&quot;: {&#10;    &quot;x_min&quot;: 0.25,&#10;    &quot;x_max&quot;: 0.75,&#10;    &quot;y_min&quot;: 0.25,&#10;    &quot;y_max&quot;: 0.85&#10;  },&#10;  &quot;thresholds&quot;: {&#10;    &quot;limite_vazia&quot;: 0.70,&#10;    &quot;limite_cheia&quot;: 0.55,&#10;    &quot;threshold_binary&quot;: 127&#10;  },&#10;  &quot;filtros&quot;: {&#10;    &quot;tamanho_historico&quot;: 10,&#10;    &quot;historico_distancias&quot;: 30,&#10;    &quot;kernel_morph_size&quot;: 5,&#10;    &quot;grid_medicao_size&quot;: 3&#10;  },&#10;  &quot;visualizacao&quot;: {&#10;    &quot;mostrar_fps&quot;: true,&#10;    &quot;mostrar_grid&quot;: true,&#10;    &quot;mostrar_ir&quot;: true,&#10;    &quot;colormap&quot;: 2&#10;  },&#10;  &quot;sons&quot;: {&#10;    &quot;beep_mudanca_status&quot;: true,&#10;    &quot;beep_frequencia&quot;: 1000,&#10;    &quot;beep_duracao&quot;: 200&#10;  }&#10;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/explicacao_V3.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/explicacao_V3.md" />
              <option name="updatedContent" value="# Sistema de Detecção de Nível V3 - Documentação Técnica&#10;&#10;##  Visão Geral&#10;&#10;O **verificar_caixaV3.py** é a versão mais avançada e robusta do sistema de detecção de nível de caixas/caçambas. Combina as melhores técnicas das versões anteriores e adiciona inovações significativas.&#10;&#10;---&#10;&#10;##  Principais Inovações da V3&#10;&#10;### 1. **Detecção por Segmentação de Profundidade**&#10;❌ **V1/V2:** Detectavam bordas visuais (afetadas por iluminação)  &#10;✅ **V3:** Segmenta objetos por profundidade (independente de iluminação)&#10;&#10;### 2. **Sistema de Grid 3x3 para Medição**&#10;❌ **V1/V2:** Mediam a região inteira de uma vez  &#10;✅ **V3:** Divide em 9 células e calcula mediana das medianas (super robusto!)&#10;&#10;### 3. **Filtro Temporal com Histórico**&#10;❌ **V1/V2:** Status mudava instantaneamente (instável)  &#10;✅ **V3:** Status só muda se 70% do histórico concordar (estável)&#10;&#10;### 4. **Triple Stream (RGB + IR + Depth)**&#10;❌ **V1/V2:** Usavam 2 streams  &#10;✅ **V3:** Usa 3 streams simultaneamente para máxima versatilidade&#10;&#10;### 5. **Estatísticas em Tempo Real**&#10;❌ **V1/V2:** Informações básicas  &#10;✅ **V3:** FPS, confiança, histórico, área, contador de frames&#10;&#10;### 6. **Visualização Profissional**&#10;❌ **V1/V2:** Interface simples  &#10;✅ **V3:** 3 janelas com painéis, barra de confiança, overlay de grid&#10;&#10;---&#10;&#10;##  Arquitetura Técnica&#10;&#10;### Pipeline de Processamento&#10;&#10;```&#10;┌─────────────────────────────────────────────────────────────┐&#10;│                    CAPTURA DE FRAMES                         │&#10;│  RGB Color + Infrared + Depth (640x480 @ 30fps)            │&#10;└──────────────────────┬──────────────────────────────────────┘&#10;                       ↓&#10;┌─────────────────────────────────────────────────────────────┐&#10;│              APLICAÇÃO DE FILTROS CASCATA                    │&#10;│  Decimation → Spatial → Temporal → Hole Filling             │&#10;└──────────────────────┬──────────────────────────────────────┘&#10;                       ↓&#10;┌─────────────────────────────────────────────────────────────┐&#10;│         SEGMENTAÇÃO POR PROFUNDIDADE                         │&#10;│  Máscara: 0.45m &lt; profundidade &lt; 0.85m                     │&#10;│  Operações morfológicas: Close → Open                       │&#10;└──────────────────────┬──────────────────────────────────────┘&#10;                       ↓&#10;┌─────────────────────────────────────────────────────────────┐&#10;│           DETECÇÃO DE CONTORNOS                              │&#10;│  findContours → Filtrar por área &gt; 5000px                   │&#10;│  Selecionar maior contorno válido                           │&#10;└──────────────────────┬──────────────────────────────────────┘&#10;                       ↓&#10;┌─────────────────────────────────────────────────────────────┐&#10;│              MEDIÇÃO EM GRID 3x3                             │&#10;│  9 células independentes                                     │&#10;│  Mediana de cada célula                                      │&#10;│  Mediana das 9 medianas = resultado final                   │&#10;└──────────────────────┬──────────────────────────────────────┘&#10;                       ↓&#10;┌─────────────────────────────────────────────────────────────┐&#10;│           ESTABILIZAÇÃO TEMPORAL                             │&#10;│  Histórico de 10 frames                                      │&#10;│  Status final = maioria dos últimos 10 frames               │&#10;└──────────────────────┬──────────────────────────────────────┘&#10;                       ↓&#10;┌─────────────────────────────────────────────────────────────┐&#10;│        CÁLCULO DE MÉTRICAS E VISUALIZAÇÃO                    │&#10;│  Altura, percentual, confiança, FPS                         │&#10;└─────────────────────────────────────────────────────────────┘&#10;```&#10;&#10;---&#10;&#10;##  Detalhamento das Técnicas Avançadas&#10;&#10;### 1. Segmentação por Profundidade&#10;&#10;**Conceito:**&#10;Ao invés de procurar bordas visuais (que dependem de iluminação), segmentamos objetos pela distância da câmera.&#10;&#10;**Implementação:**&#10;```python&#10;depth_meters = depth_image * depth_scale&#10;&#10;# Criar máscara: objetos entre 45cm e 85cm&#10;mask_roi = (depth_meters &gt; 0.45) &amp; (depth_meters &lt; 0.85)&#10;```&#10;&#10;**Por que funciona melhor?**&#10;- ✅ Não depende de iluminação (funciona no escuro total)&#10;- ✅ Não é afetado por cores ou texturas&#10;- ✅ Separa objetos por &quot;camadas&quot; de profundidade&#10;- ✅ Robusto contra sombras e reflexos&#10;&#10;### 2. Operações Morfológicas&#10;&#10;**Close (Fechamento):**&#10;```python&#10;cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)&#10;```&#10;- Remove pequenos buracos dentro da região&#10;- Conecta partes separadas por pequenos gaps&#10;- Útil quando poeira &quot;fura&quot; a detecção&#10;&#10;**Open (Abertura):**&#10;```python&#10;cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)&#10;```&#10;- Remove pequenos objetos isolados (ruído)&#10;- Suaviza bordas irregulares&#10;- Elimina falsos positivos&#10;&#10;**Ordem importa:** Close primeiro (une), Open depois (limpa)&#10;&#10;### 3. Medição em Grid 3x3&#10;&#10;**Por que dividir em células?**&#10;&#10;Imagine uma caixa com:&#10;- Canto esquerdo: objeto até 15cm&#10;- Centro: objeto até 10cm  &#10;- Canto direito: objeto até 18cm&#10;&#10;**Abordagem antiga (média simples):**&#10;```&#10;Média = (15 + 10 + 18) / 3 = 14.33cm&#10;```&#10;Resultado impreciso se houver outliers.&#10;&#10;**Abordagem V3 (grid + mediana dupla):**&#10;```&#10;Célula 1 (esquerda): mediana = 15cm&#10;Célula 2 (centro): mediana = 10cm&#10;Célula 3 (direita): mediana = 18cm&#10;Célula 4-9: ... (outros valores)&#10;&#10;Resultado final: mediana([15, 10, 18, ...]) = valor robusto&#10;```&#10;&#10;**Vantagens:**&#10;- ✅ Cada célula elimina outliers locais&#10;- ✅ Mediana global elimina células anômalas&#10;- ✅ Dupla proteção contra ruído&#10;- ✅ Medição mais precisa em superfícies irregulares&#10;&#10;**Visualização:**&#10;```&#10;┌─────┬─────┬─────┐&#10;│  1  │  2  │  3  │  Cada célula calcula&#10;├─────┼─────┼─────┤  sua própria mediana&#10;│  4  │  5  │  6  │  &#10;├─────┼─────┼─────┤  Depois: mediana das 9&#10;│  7  │  8  │  9  │&#10;└─────┴─────┴─────┘&#10;```&#10;&#10;### 4. Estabilização Temporal (Filtro de Maioria)&#10;&#10;**Problema:** Medições oscilam frame a frame&#10;```&#10;Frame 1: VAZIA&#10;Frame 2: PARCIAL (ruído!)&#10;Frame 3: VAZIA&#10;Frame 4: VAZIA&#10;```&#10;&#10;**Solução V3:** Histórico de decisões&#10;```python&#10;historico_status = deque(maxlen=10)  # Últimos 10 frames&#10;historico_status.append(status_atual)&#10;&#10;# Contar votos&#10;votos = {&#10;    &quot;VAZIA&quot;: historico_status.count(&quot;VAZIA&quot;),&#10;    &quot;PARCIAL&quot;: historico_status.count(&quot;PARCIAL&quot;),&#10;    &quot;CHEIA&quot;: historico_status.count(&quot;CHEIA&quot;)&#10;}&#10;&#10;# Status final = maioria&#10;status_estavel = max(votos, key=votos.get)&#10;```&#10;&#10;**Resultado:**&#10;- Se 7/10 frames dizem &quot;VAZIA&quot; → status = VAZIA&#10;- Se 6/10 dizem &quot;PARCIAL&quot; → status = PARCIAL&#10;- Elimina oscilações causadas por ruído&#10;&#10;**Configurável:**&#10;```python&#10;TAMANHO_HISTORICO = 10  # Aumentar = mais estável, mais lento&#10;                         # Diminuir = mais rápido, menos estável&#10;```&#10;&#10;### 5. Cálculo de Confiança&#10;&#10;**Métrica:** Desvio padrão das medições recentes&#10;&#10;```python&#10;desvio_padrao = np.std(historico_distancias)&#10;confianca = 100 - (desvio_padrao * 1000)&#10;```&#10;&#10;**Interpretação:**&#10;- **Confiança &gt; 70%** (verde): Medições estáveis, resultado confiável&#10;- **Confiança 40-70%** (laranja): Medições oscilando, cuidado&#10;- **Confiança &lt; 40%** (vermelho): Medições muito instáveis, resultado duvidoso&#10;&#10;**Por que importa:**&#10;- Você sabe quando confiar na medição&#10;- Útil para alertas automáticos (só acionar se confiança &gt; 80%)&#10;- Detecta problemas (poeira, vibração, objeto em movimento)&#10;&#10;---&#10;&#10;##  Interface Visual Detalhada&#10;&#10;### Janela 1: &quot;Sistema de Deteccao V3&quot; (Principal)&#10;&#10;**Painel Superior (preto):**&#10;```&#10;┌────────────────────────────────────────────┐&#10;│ STATUS: PARCIAL                            │ ← Grande, colorido&#10;│ Dist: 0.625m (9 pts)                      │ ← Detalhes da medição&#10;│ CAIXA DETECTADA                            │ ← Modo de detecção&#10;│ Altura: 10.0cm | 50%                       │ ← Resultado&#10;└────────────────────────────────────────────┘&#10;```&#10;&#10;**Painel Lateral Direito (preto):**&#10;```&#10;┌──────────────────┐&#10;│ ESTATISTICAS     │&#10;│ Confianca: 85%   │ ← Qualidade da medição&#10;│ FPS: 28.5        │ ← Performance&#10;│ Frames: 1247     │ ← Contador&#10;│ Area: 12450px²   │ ← Tamanho da caixa&#10;│ Historico: 10/10 │ ← Buffer cheio&#10;│ ████████░░░░░░   │ ← Barra de confiança&#10;└──────────────────┘&#10;```&#10;&#10;**Região Central:**&#10;-  Contorno amarelo: polígono detectado&#10;-  Retângulo magenta: bounding box&#10;-  Retângulo grosso colorido: status&#10;- ⬜ Mini-retângulos: grid 3x3 de medição&#10;&#10;**Rodapé:**&#10;```&#10;Pressione 'q' para sair | V3 - Deteccao Hibrida&#10;```&#10;&#10;### Janela 2: &quot;Mapa de Profundidade - V3&quot;&#10;&#10;- Mapa de calor (JET colormap)&#10;- Azul = longe, Vermelho = perto&#10;- Contorno branco sobreposto na caixa detectada&#10;- Blend 70/30 para ver o mapa + detecção&#10;&#10;### Janela 3: &quot;Visao Infravermelho&quot;&#10;&#10;- Feed do sensor IR em escala de cinza&#10;- Texto: &quot;VISAO IR (Funciona no Escuro)&quot;&#10;- Prova visual de que funciona sem luz&#10;&#10;---&#10;&#10;##  Comparação: V1 vs V2 vs V3&#10;&#10;| Aspecto | V1 (verificar_caixa) | V2 (verificar_caixaV2) | V3 (verificar_caixaV3) |&#10;|---------|---------------------|----------------------|----------------------|&#10;| **Detecção** | Bordas IR + contornos | Bordas RGB + contornos | Segmentação por profundidade |&#10;| **Iluminação** | Funciona no escuro (IR) | Precisa de luz (RGB) | Funciona no escuro (IR+RGB) |&#10;| **Medição** | Mediana simples | Mediana de região | Grid 3x3 + dupla mediana |&#10;| **Estabilidade** | Sem filtro temporal | Sem filtro temporal | Histórico de 10 frames |&#10;| **Confiança** | Não calcula | Não calcula | Métrica de desvio padrão |&#10;| **Visualização** | 2 janelas básicas | 2 janelas + info | 3 janelas profissionais |&#10;| **Estatísticas** | Nenhuma | Básicas | FPS, frames, confiança, área |&#10;| **Filtros** | Spatial + Temporal | Spatial + Temporal | +Decimation +Hole Filling |&#10;| **Robustez** | Alta | Média | Muito Alta |&#10;| **Performance** | ~30 FPS | ~30 FPS | ~25-28 FPS (mais processamento) |&#10;| **Complexidade** | Média | Baixa | Alta |&#10;| **Melhor para** | Ambientes industriais escuros | Testes rápidos bem iluminados | Aplicações profissionais críticas |&#10;&#10;---&#10;&#10;## ⚙️ Parâmetros Configuráveis&#10;&#10;### Alturas e Distâncias&#10;```python&#10;ALTURA_CAMERA_CHAO = 0.725  # Medir com trena&#10;ALTURA_CAIXA = 0.20         # Altura real da caixa&#10;TOLERANCIA = 0.03           # Margem de erro (3cm)&#10;```&#10;&#10;### Filtros de Profundidade&#10;```python&#10;CLIP_MIN = 0.3              # Ignora objetos &lt; 30cm&#10;CLIP_MAX = 1.5              # Ignora objetos &gt; 150cm&#10;PROFUNDIDADE_MIN_CAIXA = 0.45  # Camada mínima da caixa&#10;PROFUNDIDADE_MAX_CAIXA = 0.85  # Camada máxima da caixa&#10;```&#10;&#10;### Detecção&#10;```python&#10;AREA_MINIMA_PIXELS = 5000   # Área mínima do contorno&#10;```&#10;&#10;### Estabilização&#10;```python&#10;TAMANHO_HISTORICO = 10      # Frames no histórico (5-20 recomendado)&#10;```&#10;&#10;### Spatial Filter&#10;```python&#10;spatial.set_option(rs.option.filter_magnitude, 2)      # 1-5&#10;spatial.set_option(rs.option.filter_smooth_alpha, 0.5) # 0.0-1.0&#10;spatial.set_option(rs.option.filter_smooth_delta, 20)  # 1-50&#10;```&#10;&#10;### Temporal Filter&#10;```python&#10;temporal.set_option(rs.option.filter_smooth_alpha, 0.4) # 0.0-1.0&#10;temporal.set_option(rs.option.filter_smooth_delta, 20)  # 1-50&#10;```&#10;&#10;---&#10;&#10;##  Conceitos para Explicar&#10;&#10;### 1. Por que Segmentação por Profundidade é Superior?&#10;&#10;**Analogia:** &#10;Imagine que você está em uma sala escura procurando uma caixa.&#10;&#10;- **Detecção por bordas (V1/V2):** Você usa uma lanterna e procura as linhas da caixa. Se estiver escuro demais, não vê nada.&#10;- **Detecção por profundidade (V3):** Você estica os braços e detecta o que está perto vs longe. Funciona no escuro total!&#10;&#10;### 2. Grid 3x3: Mediana da Mediana&#10;&#10;**Analogia:**&#10;Você quer saber a altura média de um grupo, mas tem 3 mentirosos.&#10;&#10;- **Média simples:** Os mentirosos distorcem o resultado&#10;- **Mediana:** Ordena e pega o valor do meio, ignora extremos&#10;- **Grid 3x3 + dupla mediana:** Primeiro elimina mentirosos locais, depois globais&#10;&#10;### 3. Histórico Temporal&#10;&#10;**Analogia:**&#10;Você assiste 10 vídeos de uma pessoa e em 9 ela está sorrindo, em 1 ela está séria.&#10;- **Conclusão V1/V2:** &quot;Ela mudou de humor!&quot; (instável)&#10;- **Conclusão V3:** &quot;Ela está feliz, aquele frame sério foi atípico&quot; (estável)&#10;&#10;### 4. Confiança Baseada em Desvio&#10;&#10;**Analogia:**&#10;- **Baixo desvio (alta confiança):** Você sempre chega ao trabalho entre 8:58 e 9:02 → padrão previsível&#10;- **Alto desvio (baixa confiança):** Você chega entre 8:00 e 10:00 → padrão imprevisível&#10;&#10;---&#10;&#10;##  Como Usar&#10;&#10;### Instalação&#10;```bash&#10;pip install pyrealsense2 opencv-python numpy&#10;```&#10;&#10;### Execução&#10;```bash&#10;python verificar_caixaV3.py&#10;```&#10;&#10;### Calibração&#10;&#10;1. **Medir altura da câmera:**&#10;   - Use uma trena do chão até a lente&#10;   - Atualize `ALTURA_CAMERA_CHAO`&#10;&#10;2. **Medir altura da caixa:**&#10;   - Meça com régua&#10;   - Atualize `ALTURA_CAIXA`&#10;&#10;3. **Ajustar camadas de profundidade:**&#10;   - Execute o programa&#10;   - Observe o mapa de profundidade&#10;   - Ajuste `PROFUNDIDADE_MIN_CAIXA` e `PROFUNDIDADE_MAX_CAIXA` se necessário&#10;&#10;4. **Testar estabilidade:**&#10;   - Se status oscilar muito: aumente `TAMANHO_HISTORICO`&#10;   - Se resposta muito lenta: diminua `TAMANHO_HISTORICO`&#10;&#10;---&#10;&#10;##  Troubleshooting&#10;&#10;### Problema: Não detecta a caixa&#10;**Soluções:**&#10;- Diminuir `AREA_MINIMA_PIXELS` (de 5000 para 3000)&#10;- Ajustar `PROFUNDIDADE_MIN_CAIXA` e `PROFUNDIDADE_MAX_CAIXA`&#10;- Verificar se a caixa está na faixa de profundidade esperada&#10;&#10;### Problema: Confiança sempre baixa&#10;**Soluções:**&#10;- Aumentar potência do laser (já no máximo no código)&#10;- Estabilizar a câmera (vibração causa oscilações)&#10;- Melhorar iluminação (ajuda o processamento)&#10;- Aumentar `TAMANHO_HISTORICO` para suavizar mais&#10;&#10;### Problema: FPS muito baixo (&lt; 20)&#10;**Soluções:**&#10;- Reduzir resolução: `640x480` → `424x240`&#10;- Remover janela de IR se não usar&#10;- Diminuir `grid_size` de 3 para 2 (grid 2x2)&#10;- Comentar `hole_filling` filter&#10;&#10;### Problema: Status muda muito lentamente&#10;**Soluções:**&#10;- Diminuir `TAMANHO_HISTORICO` de 10 para 5&#10;- Ajustar lógica de maioria para 60% ao invés de 70%&#10;&#10;---&#10;&#10;##  Casos de Uso Reais&#10;&#10;### 1. Linha de Produção Industrial&#10;- **Cenário:** Caixas passam em esteira, precisa saber se estão cheias&#10;- **V3 vantagens:** &#10;  - Estabilização temporal evita falsos positivos&#10;  - Funciona com iluminação variável&#10;  - Confiança indica se pode tomar decisão automatizada&#10;&#10;### 2. Caçambas de Caminhão&#10;- **Cenário:** Monitorar nível de carga em caminhões&#10;- **V3 vantagens:**&#10;  - IR funciona à noite&#10;  - Grid 3x3 lida com carga irregular&#10;  - Robusto contra poeira&#10;&#10;### 3. Silos e Tanques&#10;- **Cenário:** Medir nível de materiais a granel&#10;- **V3 vantagens:**&#10;  - Medição por profundidade não depende de cor/textura&#10;  - Histórico temporal filtra movimentação do material&#10;  - Confiança detecta problemas de medição&#10;&#10;---&#10;&#10;##  Melhorias Futuras Possíveis&#10;&#10;### 1. Machine Learning para Classificação&#10;- Treinar CNN para identificar tipos de objetos na caixa&#10;- YOLO para detectar múltiplas caixas simultaneamente&#10;&#10;### 2. Tracking Multi-Objeto&#10;- Rastrear múltiplas caixas com IDs únicos&#10;- Útil para linhas de produção com várias estações&#10;&#10;### 3. Integração IoT&#10;- Enviar dados para servidor (MQTT/HTTP)&#10;- Dashboard web em tempo real&#10;- Alertas por email/SMS&#10;&#10;### 4. Calibração Automática&#10;- Detectar automaticamente altura da câmera&#10;- Aprender dimensões da caixa por observação&#10;&#10;### 5. Predição de Tendências&#10;- Usar histórico longo para prever quando ficará cheia&#10;- ML time series (LSTM) para estimar tempo restante&#10;&#10;---&#10;&#10;##  Conclusão&#10;&#10;A **V3** é a versão mais completa e profissional do sistema:&#10;&#10;✅ **Mais robusta:** Detecção por profundidade  &#10;✅ **Mais precisa:** Grid 3x3 + dupla mediana  &#10;✅ **Mais estável:** Histórico temporal  &#10;✅ **Mais confiável:** Métrica de confiança  &#10;✅ **Mais informativa:** Estatísticas em tempo real  &#10;✅ **Mais versátil:** 3 streams (RGB+IR+Depth)  &#10;&#10;**Recomendação de uso:**&#10;- **V1:** Ambientes industriais escuros com poeira&#10;- **V2:** Testes rápidos e prototipagem&#10;- **V3:** Aplicações profissionais críticas que exigem máxima confiabilidade&#10;&#10;---&#10;&#10;**Última atualização:** 30 Janeiro 2026  &#10;**Versão:** 3.0  &#10;**Autor:** Sistema Avançado de Visão Computacional&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/explicacao_deteccao_automatica.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/explicacao_deteccao_automatica.md" />
              <option name="updatedContent" value="# Detecção Automática da Área da Caixa/Caçamba&#10;&#10;##  Objetivo da Melhoria&#10;&#10;O algoritmo agora **identifica automaticamente a região da caixa/caçamba** ao invés de apenas medir um ponto fixo no centro da imagem. Isso torna o sistema mais robusto e preciso.&#10;&#10;---&#10;&#10;##  O Que Mudou?&#10;&#10;### ❌ Antes (Versão Original)&#10;- Media apenas o **centro fixo** da imagem (100x100 pixels)&#10;- Dependia de posicionamento preciso da câmera&#10;- Se a caixa não estivesse perfeitamente centralizada, media o fundo&#10;&#10;### ✅ Agora (Com Detecção Automática)&#10;- **Detecta automaticamente** os contornos da caixa&#10;- Mede **toda a área interna** da caixa detectada&#10;- Funciona mesmo se a caixa não estiver perfeitamente centralizada&#10;- **Fallback inteligente**: se não detectar caixa, usa o centro como antes&#10;&#10;---&#10;&#10;##  Como Funciona a Detecção?&#10;&#10;### Passo 1: Processamento da Imagem&#10;```python&#10;# Converter para escala de cinza&#10;gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)&#10;&#10;# Suavizar para reduzir ruído&#10;blurred = cv2.GaussianBlur(gray, (7, 7), 0)&#10;```&#10;- Cinza facilita processamento (1 canal ao invés de 3)&#10;- Blur remove ruído que poderia gerar falsos contornos&#10;&#10;### Passo 2: Detecção de Bordas&#10;```python&#10;# Algoritmo Canny detecta mudanças abruptas de intensidade&#10;edges = cv2.Canny(blurred, 50, 150)&#10;&#10;# Dilatar conecta bordas quebradas&#10;kernel = np.ones((3, 3), np.uint8)&#10;edges = cv2.dilate(edges, kernel, iterations=2)&#10;```&#10;- **Canny Edge Detection**: encontra bordas na imagem&#10;- **Dilatação**: conecta linhas quebradas, formando contornos fechados&#10;&#10;### Passo 3: Encontrar Contornos&#10;```python&#10;contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)&#10;```&#10;- `RETR_EXTERNAL`: pega apenas contornos externos (ignora internos)&#10;- `CHAIN_APPROX_SIMPLE`: simplifica os pontos do contorno&#10;&#10;### Passo 4: Filtrar e Selecionar a Caixa&#10;```python&#10;for contour in contours:&#10;    area = cv2.contourArea(contour)&#10;    if area &gt; AREA_MINIMA_CAIXA:  # Maior que 3000 pixels&#10;        perimeter = cv2.arcLength(contour, True)&#10;        approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)&#10;        &#10;        if len(approx) &gt;= 4:  # Retângulo ou polígono de 4+ lados&#10;            if area &gt; maior_area:&#10;                maior_area = area&#10;                melhor_contorno = approx&#10;                caixa_detectada = True&#10;```&#10;&#10;**Filtros aplicados:**&#10;1. ✅ Área mínima de 3000 pixels (ignora objetos pequenos)&#10;2. ✅ Deve ter pelo menos 4 vértices (formato retangular)&#10;3. ✅ Seleciona o maior contorno válido (provavelmente a caixa)&#10;&#10;### Passo 5: Medir Profundidade na Área Detectada&#10;```python&#10;# Obter retângulo delimitador da caixa&#10;x1, y1, w_box, h_box = cv2.boundingRect(melhor_contorno)&#10;x2 = x1 + w_box&#10;y2 = y1 + h_box&#10;&#10;# Extrair TODA a região de profundidade dentro da caixa&#10;regiao_depth = depth_image[y1:y2, x1:x2]&#10;&#10;# Calcular mediana (robusto contra outliers)&#10;regiao_valida = regiao_depth[regiao_depth &gt; 0]&#10;distancia_mediana = np.median(regiao_valida) * depth_scale&#10;```&#10;&#10;---&#10;&#10;##  Comparação: Centro Fixo vs Detecção Automática&#10;&#10;| Aspecto | Centro Fixo | Detecção Automática |&#10;|---------|-------------|---------------------|&#10;| **Área medida** | 100x100 pixels (10.000 px) | Toda a caixa (~10.000-50.000+ px) |&#10;| **Precisão** | Depende de centralização perfeita | Adaptável à posição da caixa |&#10;| **Robustez** | Falha se caixa desalinhada | Funciona com caixa desalinhada |&#10;| **Pontos de dados** | ~10.000 pixels | 30.000+ pixels (3x mais dados) |&#10;| **Confiabilidade** | Média | Alta |&#10;&#10;---&#10;&#10;##  Visualização na Tela&#10;&#10;### Quando a Caixa é Detectada:&#10;-  **Contorno amarelo (cyan)**: desenha o polígono detectado&#10;-  **Retângulo magenta**: caixa delimitadora (bounding box)&#10;-  **Retângulo colorido grosso**: status (verde=cheia, laranja=parcial, vermelho=vazia)&#10;-  **Texto**: &quot;CAIXA DETECTADA&quot; + área em pixels²&#10;&#10;### Quando NÃO Detecta a Caixa (Fallback):&#10;- ✝️ **Cruz branca**: marca o centro da imagem&#10;-  **Retângulo central**: área 100x100 sendo medida&#10;-  **Texto**: &quot;Modo Centro&quot; ou &quot;Procurando caixa...&quot;&#10;&#10;---&#10;&#10;## ️ Parâmetros Configuráveis&#10;&#10;### AREA_MINIMA_CAIXA = 3000&#10;- Área mínima em pixels para considerar um contorno válido&#10;- **Aumentar** se detectar objetos pequenos indesejados&#10;- **Diminuir** se não estiver detectando a caixa&#10;&#10;### TAMANHO_KERNEL_BLUR = 7&#10;- Tamanho do filtro de suavização (deve ser ímpar)&#10;- **Aumentar** (9, 11) para mais suavização (ambientes ruidosos)&#10;- **Diminuir** (3, 5) para mais detalhes (ambientes limpos)&#10;&#10;### Parâmetros do Canny&#10;```python&#10;edges = cv2.Canny(blurred, 50, 150)&#10;```&#10;- **Primeiro valor (50)**: limiar inferior (bordas fracas)&#10;- **Segundo valor (150)**: limiar superior (bordas fortes)&#10;- **Aumentar ambos**: detecta apenas bordas muito fortes&#10;- **Diminuir ambos**: detecta mais bordas (pode pegar ruído)&#10;&#10;---&#10;&#10;##  Casos de Uso e Comportamento&#10;&#10;### Caso 1: Caixa Perfeitamente Posicionada&#10;```&#10;Comportamento: Detecta contornos, mede toda área&#10;Status: ✅ CAIXA DETECTADA&#10;Precisão: Máxima (30.000+ pontos)&#10;```&#10;&#10;### Caso 2: Caixa Levemente Desalinhada&#10;```&#10;Comportamento: Detecta contornos, ajusta região automaticamente&#10;Status: ✅ CAIXA DETECTADA&#10;Precisão: Alta (adapta-se à posição)&#10;```&#10;&#10;### Caso 3: Caixa Muito Desalinhada ou com Obstáculos&#10;```&#10;Comportamento: Pode não detectar contornos claros&#10;Status: ⚠️ Modo Centro (fallback)&#10;Precisão: Média (depende do que há no centro)&#10;```&#10;&#10;### Caso 4: Sem Caixa na Visão&#10;```&#10;Comportamento: Não detecta contornos, usa centro&#10;Status: ⚠️ Procurando caixa...&#10;Precisão: N/A (aguardando caixa)&#10;```&#10;&#10;---&#10;&#10;##  Detalhes Técnicos Importantes&#10;&#10;### Por que usar approxPolyDP?&#10;```python&#10;approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)&#10;```&#10;- Simplifica contornos complexos em polígonos&#10;- `0.02 * perimeter`: tolerância de aproximação (2% do perímetro)&#10;- Transforma curvas em linhas retas&#10;- Facilita identificar formas geométricas (retângulos)&#10;&#10;### Por que usar RETR_EXTERNAL?&#10;- Ignora contornos internos (objetos dentro da caixa)&#10;- Foca apenas no contorno externo da caixa&#10;- Evita confusão com objetos dentro&#10;&#10;### Por que calcular a mediana em vez da média?&#10;```python&#10;distancia_mediana = np.median(regiao_valida)&#10;```&#10;- **Mediana é robusta contra outliers**&#10;- Se 10% dos pixels tiverem ruído, a mediana não é afetada&#10;- Média seria distorcida por valores extremos&#10;- Crucial em ambientes com poeira/reflexos&#10;&#10;---&#10;&#10;##  Melhorias Futuras Possíveis&#10;&#10;### 1. Detecção Multi-Caixa&#10;- Detectar múltiplas caixas na mesma cena&#10;- Útil para linhas de produção com várias estações&#10;&#10;### 2. Calibração Automática&#10;- Aprender automaticamente as dimensões da caixa&#10;- Adaptar AREA_MINIMA dinamicamente&#10;&#10;### 3. Histórico de Detecções&#10;- Usar frames anteriores para estabilizar detecção&#10;- Filtro temporal para evitar &quot;piscadas&quot; na detecção&#10;&#10;### 4. Machine Learning&#10;- Treinar modelo para reconhecer formas específicas&#10;- YOLOv8 ou Mask R-CNN para detecção mais precisa&#10;&#10;### 5. Detecção por Profundidade&#10;- Usar o mapa de profundidade para segmentar a caixa&#10;- Mais robusto que bordas visuais em ambientes complexos&#10;&#10;---&#10;&#10;##  Conceitos para Explicar ao Orientando&#10;&#10;### 1. Visão Computacional vs Regra Fixa&#10;**Antes:** &quot;Sempre olhe no ponto (320, 240)&quot;  &#10;**Agora:** &quot;Encontre onde está a caixa, depois meça lá&quot;&#10;&#10;### 2. Pipeline de Processamento&#10;```&#10;Imagem → Cinza → Blur → Bordas → Contornos → Filtros → Seleção&#10;```&#10;Cada etapa prepara os dados para a próxima&#10;&#10;### 3. Trade-off: Simplicidade vs Robustez&#10;- Centro fixo: simples, mas frágil&#10;- Detecção automática: complexa, mas robusta&#10;&#10;### 4. Fallback Strategies&#10;Sempre ter um plano B quando a detecção falha&#10;&#10;---&#10;&#10;## ✅ Checklist de Teste&#10;&#10;- [ ] Caixa centralizada → detecta e mede corretamente&#10;- [ ] Caixa desalinhada 5cm → ainda detecta&#10;- [ ] Caixa desalinhada 10cm → ainda detecta&#10;- [ ] Sem caixa → entra em modo centro/busca&#10;- [ ] Objeto pequeno na cena → ignora (área &lt; 3000)&#10;- [ ] Caixa vazia → status VAZIA&#10;- [ ] Objeto dentro até metade → status PARCIAL&#10;- [ ] Objeto até borda → status CHEIA&#10;&#10;---&#10;&#10;##  Como Usar o Código Atualizado&#10;&#10;```bash&#10;python verificar_caixaV2.py&#10;```&#10;&#10;### O que você verá:&#10;1. **Contornos detectados em tempo real**&#10;2. **Status**: VAZIA / PARCIAL / CHEIA&#10;3. **Informações**:&#10;   - Distância medida&#10;   - Status de detecção (CAIXA DETECTADA ou Modo Centro)&#10;   - Altura do conteúdo&#10;   - Percentual de preenchimento&#10;   - Área da caixa em pixels²&#10;&#10;### Teclas:&#10;- **'q'**: sair do programa&#10;&#10;---&#10;&#10;##  Conclusão&#10;&#10;A detecção automática de área torna o sistema:&#10;- ✅ **Mais robusto**: funciona com caixa desalinhada&#10;- ✅ **Mais preciso**: usa mais pontos de dados&#10;- ✅ **Mais inteligente**: adapta-se à cena&#10;- ✅ **Mais confiável**: fallback quando não detecta&#10;&#10;É um upgrade significativo sobre a medição de ponto fixo! &#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/medir_profundidade.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/medir_profundidade.py" />
              <option name="updatedContent" value="import pyrealsense2 as rs&#10;import numpy as np&#10;import cv2&#10;&#10;&quot;&quot;&quot;&#10;Algoritmo para medir a altura da câmera RealSense até o chão.&#10;Pressione 'ESC' para sair.&#10;&quot;&quot;&quot;&#10;&#10;# --- Configuração da RealSense ---&#10;pipeline = rs.pipeline()&#10;config = rs.config()&#10;&#10;# Habilitar streams de profundidade e cor&#10;config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)&#10;config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)&#10;&#10;print(&quot;Iniciando câmera RealSense...&quot;)&#10;profile = pipeline.start(config)&#10;&#10;# Obter escala de profundidade&#10;depth_sensor = profile.get_device().first_depth_sensor()&#10;depth_scale = depth_sensor.get_depth_scale()&#10;&#10;# Alinhar frames de profundidade com cor&#10;align_to = rs.stream.color&#10;align = rs.align(align_to)&#10;&#10;print(&quot;\n&quot; + &quot;=&quot;*60)&#10;print(&quot;MEDIDOR DE ALTURA DA CÂMERA ATÉ O CHÃO&quot;)&#10;print(&quot;=&quot;*60)&#10;print(&quot;\nAponte a câmera para o chão diretamente abaixo dela.&quot;)&#10;print(&quot;A medição será feita no centro da imagem (cruz verde).&quot;)&#10;print(&quot;\nPressione 'ESC' para sair.\n&quot;)&#10;&#10;try:&#10;    while True:&#10;        # Capturar frames&#10;        frames = pipeline.wait_for_frames()&#10;        aligned_frames = align.process(frames)&#10;        &#10;        aligned_depth_frame = aligned_frames.get_depth_frame()&#10;        color_frame = aligned_frames.get_color_frame()&#10;        &#10;        if not aligned_depth_frame or not color_frame:&#10;            continue&#10;        &#10;        # Converter para numpy arrays&#10;        depth_image = np.asanyarray(aligned_depth_frame.get_data())&#10;        color_image = np.asanyarray(color_frame.get_data())&#10;        &#10;        # Obter dimensões da imagem&#10;        h, w = color_image.shape[:2]&#10;        center_x, center_y = w // 2, h // 2&#10;        &#10;        # Medir distância no ponto central&#10;        distancia_centro = aligned_depth_frame.get_distance(center_x, center_y)&#10;        &#10;        # Calcular média de uma região 10x10 pixels no centro para maior precisão&#10;        regiao_size = 10&#10;        x1 = max(0, center_x - regiao_size)&#10;        x2 = min(w, center_x + regiao_size)&#10;        y1 = max(0, center_y - regiao_size)&#10;        y2 = min(h, center_y + regiao_size)&#10;        &#10;        regiao_depth = depth_image[y1:y2, x1:x2]&#10;        # Filtrar valores zero (medições inválidas)&#10;        regiao_valida = regiao_depth[regiao_depth &gt; 0]&#10;        &#10;        if len(regiao_valida) &gt; 0:&#10;            distancia_media = np.mean(regiao_valida) * depth_scale&#10;        else:&#10;            distancia_media = 0.0&#10;        &#10;        # Desenhar cruz no centro da imagem&#10;        cruz_tamanho = 20&#10;        cor_cruz = (0, 255, 0)  # Verde&#10;        cv2.line(color_image, (center_x - cruz_tamanho, center_y), &#10;                 (center_x + cruz_tamanho, center_y), cor_cruz, 2)&#10;        cv2.line(color_image, (center_x, center_y - cruz_tamanho), &#10;                 (center_x, center_y + cruz_tamanho), cor_cruz, 2)&#10;        &#10;        # Desenhar retângulo da região de medição&#10;        cv2.rectangle(color_image, (x1, y1), (x2, y2), (255, 255, 0), 2)&#10;        &#10;        # Exibir informações na imagem&#10;        if distancia_media &gt; 0:&#10;            texto_altura = f&quot;ALTURA DA CAMERA: {distancia_media:.3f} m ({distancia_media*100:.1f} cm)&quot;&#10;            cor_texto = (0, 255, 0)&#10;        else:&#10;            texto_altura = &quot;SEM MEDICAO VALIDA&quot;&#10;            cor_texto = (0, 0, 255)&#10;        &#10;        # Fundo para o texto (melhor legibilidade)&#10;        cv2.rectangle(color_image, (10, 10), (w - 10, 80), (0, 0, 0), -1)&#10;        &#10;        # Textos informativos&#10;        cv2.putText(color_image, texto_altura, (20, 40),&#10;                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, cor_texto, 2)&#10;        cv2.putText(color_image, f&quot;Centro: {distancia_centro:.3f} m&quot;, (20, 65),&#10;                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)&#10;        &#10;        # Exibir a imagem&#10;        cv2.imshow('Medidor de Altura da Camera', color_image)&#10;        &#10;        # Imprimir no console&#10;        if distancia_media &gt; 0:&#10;            print(f&quot;\rAltura: {distancia_media:.3f} m ({distancia_media*100:.1f} cm) | &quot;&#10;                  f&quot;Centro: {distancia_centro:.3f} m&quot;, end='', flush=True)&#10;        &#10;        # Sair com ESC&#10;        key = cv2.waitKey(1)&#10;        if key == 27:  # ESC&#10;            break&#10;&#10;finally:&#10;    print(&quot;\n\nEncerrando...&quot;)&#10;    pipeline.stop()&#10;    cv2.destroyAllWindows()&#10;    print(&quot;Câmera desligada.&quot;)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/verificar_caixa.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/verificar_caixa.py" />
              <option name="originalContent" value="import pyrealsense2 as rs&#10;import numpy as np&#10;import cv2&#10;&#10;&#10;def rastrear_cacamba_hostil():&#10;    # --- CONFIGURAÇÕES ---&#10;    AREA_MINIMA = 10000&#10;    ALTURA_BORDA_CAMINHAO = 0.53&#10;&#10;    # Filtro de Distância (Min/Max em metros)&#10;    # Ignora poeira colada na lente (&lt; 0.5m) e fundo infinito (&gt; 6m)&#10;    CLIP_MIN = 0.5&#10;    CLIP_MAX = 6.0&#10;&#10;    # --- INICIALIZAÇÃO DA REALSENSE ---&#10;    pipeline = rs.pipeline()&#10;    config = rs.config()&#10;&#10;    # Usamos Infravermelho (IR) e Profundidade.&#10;    # O IR funciona no escuro total graças ao projetor laser da câmera.&#10;    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)&#10;    config.enable_stream(rs.stream.infrared, 1, 640, 480, rs.format.y8, 30)&#10;&#10;    print(&quot;[INFO] Iniciando rastreamento IR (Visão Noturna)...&quot;)&#10;    profile = pipeline.start(config)&#10;&#10;    # --- CONFIGURAÇÃO DE FILTROS (A &quot;Mágica&quot; contra Poeira) ---&#10;    # 1. Decimation: Reduz resolução para diminuir ruído e aumentar performance&#10;    decimation = rs.decimation_filter()&#10;    decimation.set_option(rs.option.filter_magnitude, 1)  # 1 = sem redução, aumente se tiver muito ruído&#10;&#10;    # 2. Spatial: Suaviza a superfície (tapa buracos na profundidade causados por poeira)&#10;    spatial = rs.spatial_filter()&#10;    spatial.set_option(rs.option.filter_magnitude, 2)&#10;    spatial.set_option(rs.option.filter_smooth_alpha, 0.5)&#10;    spatial.set_option(rs.option.filter_smooth_delta, 20)&#10;&#10;    # 3. Temporal: O MAIS IMPORTANTE PARA POEIRA.&#10;    # Ele compara o frame atual com os anteriores. Se um pixel (poeira) aparece e some rápido, ele é removido.&#10;    temporal = rs.temporal_filter()&#10;&#10;    # Forçar o projetor laser a ligar (caso esteja desligado)&#10;    device = profile.get_device()&#10;    depth_sensor = device.first_depth_sensor()&#10;    if depth_sensor.supports(rs.option.emitter_enabled):&#10;        depth_sensor.set_option(rs.option.emitter_enabled, 1.0)  # 1 = Ligado&#10;        # Aumentar a potência do laser para penetrar poeira (máximo costuma ser 360)&#10;        if depth_sensor.supports(rs.option.laser_power):&#10;            max_laser = depth_sensor.get_option_range(rs.option.laser_power).max&#10;            depth_sensor.set_option(rs.option.laser_power, max_laser)&#10;&#10;    depth_scale = depth_sensor.get_depth_scale()&#10;&#10;    try:&#10;        while True:&#10;            frames = pipeline.wait_for_frames()&#10;&#10;            # Alinhamento não é estritamente necessário se usarmos IR e Depth do mesmo sensor,&#10;            # mas garante precisão pixel-a-pixel.&#10;            # Nas D435/D455, o IR Esquerdo (index 1) é perfeitamente alinhado com o Depth.&#10;            ir_frame = frames.get_infrared_frame(1)&#10;            depth_frame = frames.get_depth_frame()&#10;&#10;            if not depth_frame or not ir_frame:&#10;                continue&#10;&#10;            # --- APLICAÇÃO DOS FILTROS (Limpeza da Imagem) ---&#10;            # A ordem importa: Decimation -&gt; Spatial -&gt; Temporal&#10;            filtered_depth = spatial.process(depth_frame)&#10;            filtered_depth = temporal.process(filtered_depth)&#10;&#10;            # Converter para Numpy&#10;            # A imagem IR já vem em tons de cinza (Y8), perfeita para processar&#10;            ir_image = np.asanyarray(ir_frame.get_data())&#10;            depth_image = np.asanyarray(filtered_depth.get_data())&#10;&#10;            # --- PROCESSAMENTO DE VISÃO (Agora no Espectro IR) ---&#10;&#10;            # Melhora o contraste da imagem IR para destacar as bordas da caçamba no escuro&#10;            # Equalização de histograma ajuda a ver detalhes mesmo com pouca luz refletida&#10;            ir_enhanced = cv2.equalizeHist(ir_image)&#10;&#10;            # Blur para remover ruído granulado do sensor IR&#10;            blur = cv2.GaussianBlur(ir_enhanced, (5, 5), 0)&#10;&#10;            # Detecção de Bordas&#10;            # O IR tem alto contraste nas bordas físicas, funciona muito bem&#10;            edges = cv2.Canny(blur, 50, 150)&#10;&#10;            # Dilatar as bordas ajuda a conectar linhas quebradas pela poeira&#10;            edges = cv2.dilate(edges, None, iterations=1)&#10;&#10;            contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)&#10;&#10;            melhor_retangulo = None&#10;            maior_area = 0&#10;&#10;            # Como vamos desenhar informações coloridas para o humano ver,&#10;            # convertemos o IR de volta para BGR apenas para visualização&#10;            display_image = cv2.cvtColor(ir_image, cv2.COLOR_GRAY2BGR)&#10;&#10;            for cnt in contours:&#10;                area = cv2.contourArea(cnt)&#10;                if area &gt; AREA_MINIMA:&#10;                    perimetro = cv2.arcLength(cnt, True)&#10;                    approx = cv2.approxPolyDP(cnt, 0.02 * perimetro, True)&#10;&#10;                    if len(approx) == 4:&#10;                        if area &gt; maior_area:&#10;                            maior_area = area&#10;                            melhor_retangulo = approx&#10;&#10;            # --- ANÁLISE DE PROFUNDIDADE ---&#10;            status = &quot;AGUARDANDO CAMINHAO...&quot;&#10;            cor_status = (0, 0, 255)  # Vermelho&#10;&#10;            if melhor_retangulo is not None:&#10;                cv2.drawContours(display_image, [melhor_retangulo], -1, (0, 255, 255), 2)&#10;&#10;                # Criar máscara&#10;                mascara = np.zeros(depth_image.shape, dtype=np.uint8)&#10;                cv2.drawContours(mascara, [melhor_retangulo], -1, 255, -1)&#10;&#10;                # --- TRUQUE CONTRA POEIRA NA MEDIÇÃO ---&#10;                # Em vez de pegar a média simples (que pode ser afetada por poeira flutuando),&#10;                # pegamos a MEDIANA ou filtramos pixels muito pertos (ruído)&#10;&#10;                # Extrair apenas os pixels de profundidade dentro do retângulo&#10;                pixels_validos = depth_image[mascara == 255]&#10;&#10;                if len(pixels_validos) &gt; 0:&#10;                    # Converter para metros&#10;                    distancias_metros = pixels_validos * depth_scale&#10;&#10;                    # Remover leituras absurdas (filtros de clip)&#10;                    # Ex: Se a poeira refletiu a 10cm da câmera, ignoramos&#10;                    distancias_reais = distancias_metros[&#10;                        (distancias_metros &gt; CLIP_MIN) &amp; (distancias_metros &lt; CLIP_MAX)&#10;                        ]&#10;&#10;                    if len(distancias_reais) &gt; 0:&#10;                        # Usamos a mediana para evitar outliers (picos de poeira)&#10;                        distancia_mediana = np.median(distancias_reais)&#10;&#10;                        if distancia_mediana &lt; ALTURA_BORDA_CAMINHAO:&#10;                            status = &quot;CARGA DETECTADA&quot;&#10;                            cor_status = (0, 255, 0)  # Verde&#10;&#10;                            # Cálculo de % de enchimento (estimativa simples)&#10;                            # Assumindo que o chão da caçamba está a 4.0m e a borda a 3.5m&#10;                            # E a carga sobe até 2.0m&#10;                            # Isso é apenas um exemplo, você deve calibrar com seu caminhão real&#10;                            chao_cacamba = 4.0&#10;                            altura_carga = chao_cacamba - distancia_mediana&#10;                            if altura_carga &lt; 0: altura_carga = 0&#10;&#10;                            texto_info = f&quot;Altura Carga: {altura_carga:.2f}m&quot;&#10;                        else:&#10;                            status = &quot;CACAMBA VAZIA&quot;&#10;                            cor_status = (0, 165, 255)  # Laranja&#10;                            texto_info = f&quot;Profundidade: {distancia_mediana:.2f}m&quot;&#10;&#10;                        # Desenhar texto&#10;                        x, y, w, h = cv2.boundingRect(melhor_retangulo)&#10;                        cv2.putText(display_image, texto_info, (x, y + h + 25),&#10;                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, cor_status, 2)&#10;&#10;            # --- EXIBIÇÃO ---&#10;            cv2.putText(display_image, f&quot;MODO IR - {status}&quot;, (20, 50),&#10;                        cv2.FONT_HERSHEY_SIMPLEX, 1, cor_status, 2)&#10;&#10;            # Mostra a visão do sensor IR (que vê no escuro)&#10;            cv2.imshow('Monitoramento Noturno/Poeira', display_image)&#10;&#10;            # Opcional: ver o mapa de calor da profundidade filtrada&#10;            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)&#10;            cv2.imshow('Depth Map Filtrado', depth_colormap)&#10;&#10;            if cv2.waitKey(1) &amp; 0xFF == ord('q'):&#10;                break&#10;&#10;    finally:&#10;        pipeline.stop()&#10;        cv2.destroyAllWindows()&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    rastrear_cacamba_hostil()" />
              <option name="updatedContent" value="import pyrealsense2 as rs&#10;import numpy as np&#10;import cv2&#10;&#10;&#10;def rastrear_cacamba_hostil():&#10;    # --- CONFIGURAÇÕES PARA TESTE COM CAIXA DE ISOPOR ---&#10;    # Caixa: 20cm de altura&#10;    # Câmera: 72.5cm (0.725m) do chão&#10;    &#10;    AREA_MINIMA = 5000  # Reduzido para detectar caixa menor&#10;    &#10;    # Distâncias de referência (em metros)&#10;    ALTURA_CAMERA_CHAO = 0.725  # 72.5cm&#10;    ALTURA_CAIXA = 0.20  # 20cm&#10;    ALTURA_BORDA_CAIXA = ALTURA_CAMERA_CHAO - ALTURA_CAIXA  # 0.525m até a borda&#10;    ALTURA_FUNDO_CAIXA = ALTURA_CAMERA_CHAO  # 0.725m até o fundo da caixa&#10;    &#10;    # Tolerância para detecção (em metros)&#10;    TOLERANCIA = 0.03  # 3cm de margem&#10;    &#10;    # Filtro de Distância (Min/Max em metros)&#10;    CLIP_MIN = 0.3  # Reduzido para detectar objetos mais próximos&#10;    CLIP_MAX = 1.5  # Ajustado para o ambiente de teste&#10;&#10;    # --- INICIALIZAÇÃO DA REALSENSE ---&#10;    pipeline = rs.pipeline()&#10;    config = rs.config()&#10;&#10;    # Usamos Infravermelho (IR) e Profundidade.&#10;    # O IR funciona no escuro total graças ao projetor laser da câmera.&#10;    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)&#10;    config.enable_stream(rs.stream.infrared, 1, 640, 480, rs.format.y8, 30)&#10;&#10;    print(&quot;[INFO] Iniciando rastreamento IR (Visão Noturna)...&quot;)&#10;    profile = pipeline.start(config)&#10;&#10;    # --- CONFIGURAÇÃO DE FILTROS (A &quot;Mágica&quot; contra Poeira) ---&#10;    # 1. Decimation: Reduz resolução para diminuir ruído e aumentar performance&#10;    decimation = rs.decimation_filter()&#10;    decimation.set_option(rs.option.filter_magnitude, 1)  # 1 = sem redução, aumente se tiver muito ruído&#10;&#10;    # 2. Spatial: Suaviza a superfície (tapa buracos na profundidade causados por poeira)&#10;    spatial = rs.spatial_filter()&#10;    spatial.set_option(rs.option.filter_magnitude, 2)&#10;    spatial.set_option(rs.option.filter_smooth_alpha, 0.5)&#10;    spatial.set_option(rs.option.filter_smooth_delta, 20)&#10;&#10;    # 3. Temporal: O MAIS IMPORTANTE PARA POEIRA.&#10;    # Ele compara o frame atual com os anteriores. Se um pixel (poeira) aparece e some rápido, ele é removido.&#10;    temporal = rs.temporal_filter()&#10;&#10;    # Forçar o projetor laser a ligar (caso esteja desligado)&#10;    device = profile.get_device()&#10;    depth_sensor = device.first_depth_sensor()&#10;    if depth_sensor.supports(rs.option.emitter_enabled):&#10;        depth_sensor.set_option(rs.option.emitter_enabled, 1.0)  # 1 = Ligado&#10;        # Aumentar a potência do laser para penetrar poeira (máximo costuma ser 360)&#10;        if depth_sensor.supports(rs.option.laser_power):&#10;            max_laser = depth_sensor.get_option_range(rs.option.laser_power).max&#10;            depth_sensor.set_option(rs.option.laser_power, max_laser)&#10;&#10;    depth_scale = depth_sensor.get_depth_scale()&#10;&#10;    try:&#10;        while True:&#10;            frames = pipeline.wait_for_frames()&#10;&#10;            # Alinhamento não é estritamente necessário se usarmos IR e Depth do mesmo sensor,&#10;            # mas garante precisão pixel-a-pixel.&#10;            # Nas D435/D455, o IR Esquerdo (index 1) é perfeitamente alinhado com o Depth.&#10;            ir_frame = frames.get_infrared_frame(1)&#10;            depth_frame = frames.get_depth_frame()&#10;&#10;            if not depth_frame or not ir_frame:&#10;                continue&#10;&#10;            # --- APLICAÇÃO DOS FILTROS (Limpeza da Imagem) ---&#10;            # A ordem importa: Decimation -&gt; Spatial -&gt; Temporal&#10;            filtered_depth = spatial.process(depth_frame)&#10;            filtered_depth = temporal.process(filtered_depth)&#10;&#10;            # Converter para Numpy&#10;            # A imagem IR já vem em tons de cinza (Y8), perfeita para processar&#10;            ir_image = np.asanyarray(ir_frame.get_data())&#10;            depth_image = np.asanyarray(filtered_depth.get_data())&#10;&#10;            # --- PROCESSAMENTO DE VISÃO (Agora no Espectro IR) ---&#10;&#10;            # Melhora o contraste da imagem IR para destacar as bordas da caçamba no escuro&#10;            # Equalização de histograma ajuda a ver detalhes mesmo com pouca luz refletida&#10;            ir_enhanced = cv2.equalizeHist(ir_image)&#10;&#10;            # Blur para remover ruído granulado do sensor IR&#10;            blur = cv2.GaussianBlur(ir_enhanced, (5, 5), 0)&#10;&#10;            # Detecção de Bordas&#10;            # O IR tem alto contraste nas bordas físicas, funciona muito bem&#10;            edges = cv2.Canny(blur, 50, 150)&#10;&#10;            # Dilatar as bordas ajuda a conectar linhas quebradas pela poeira&#10;            edges = cv2.dilate(edges, None, iterations=1)&#10;&#10;            contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)&#10;&#10;            melhor_retangulo = None&#10;            maior_area = 0&#10;&#10;            # Como vamos desenhar informações coloridas para o humano ver,&#10;            # convertemos o IR de volta para BGR apenas para visualização&#10;            display_image = cv2.cvtColor(ir_image, cv2.COLOR_GRAY2BGR)&#10;&#10;            for cnt in contours:&#10;                area = cv2.contourArea(cnt)&#10;                if area &gt; AREA_MINIMA:&#10;                    perimetro = cv2.arcLength(cnt, True)&#10;                    approx = cv2.approxPolyDP(cnt, 0.02 * perimetro, True)&#10;&#10;                    if len(approx) == 4:&#10;                        if area &gt; maior_area:&#10;                            maior_area = area&#10;                            melhor_retangulo = approx&#10;&#10;            # --- ANÁLISE DE PROFUNDIDADE ---&#10;            status = &quot;AGUARDANDO CAIXA...&quot;&#10;            cor_status = (128, 128, 128)  # Cinza&#10;&#10;            if melhor_retangulo is not None:&#10;                cv2.drawContours(display_image, [melhor_retangulo], -1, (0, 255, 255), 2)&#10;&#10;                # Criar máscara&#10;                mascara = np.zeros(depth_image.shape, dtype=np.uint8)&#10;                cv2.drawContours(mascara, [melhor_retangulo], -1, 255, -1)&#10;&#10;                # --- TRUQUE CONTRA POEIRA NA MEDIÇÃO ---&#10;                # Em vez de pegar a média simples (que pode ser afetada por poeira flutuando),&#10;                # pegamos a MEDIANA ou filtramos pixels muito pertos (ruído)&#10;&#10;                # Extrair apenas os pixels de profundidade dentro do retângulo&#10;                pixels_validos = depth_image[mascara == 255]&#10;&#10;                if len(pixels_validos) &gt; 0:&#10;                    # Converter para metros&#10;                    distancias_metros = pixels_validos * depth_scale&#10;&#10;                    # Remover leituras absurdas (filtros de clip)&#10;                    # Ex: Se a poeira refletiu a 10cm da câmera, ignoramos&#10;                    distancias_reais = distancias_metros[&#10;                        (distancias_metros &gt; CLIP_MIN) &amp; (distancias_metros &lt; CLIP_MAX)&#10;                        ]&#10;&#10;                    if len(distancias_reais) &gt; 0:&#10;                        # Usamos a mediana para evitar outliers (picos de poeira)&#10;                        distancia_mediana = np.median(distancias_reais)&#10;&#10;                        # Calcular a altura do conteúdo dentro da caixa&#10;                        altura_conteudo = ALTURA_FUNDO_CAIXA - distancia_mediana&#10;                        percentual_cheio = (altura_conteudo / ALTURA_CAIXA) * 100&#10;                        &#10;                        # Limitar percentual entre 0 e 100&#10;                        if percentual_cheio &lt; 0: &#10;                            percentual_cheio = 0&#10;                        elif percentual_cheio &gt; 100:&#10;                            percentual_cheio = 100&#10;&#10;                        # Classificar estado da caixa&#10;                        if distancia_mediana &gt;= (ALTURA_FUNDO_CAIXA - TOLERANCIA):&#10;                            # Distância próxima ao fundo = caixa vazia&#10;                            status = &quot;CAIXA VAZIA&quot;&#10;                            cor_status = (0, 0, 255)  # Vermelho&#10;                            texto_info = f&quot;Vazia | Dist: {distancia_mediana:.3f}m&quot;&#10;                            &#10;                        elif distancia_mediana &lt;= (ALTURA_BORDA_CAIXA + TOLERANCIA):&#10;                            # Objeto até a borda ou acima&#10;                            status = &quot;CAIXA CHEIA&quot;&#10;                            cor_status = (0, 255, 0)  # Verde&#10;                            texto_info = f&quot;Cheia {percentual_cheio:.0f}% | Alt: {altura_conteudo*100:.1f}cm&quot;&#10;                            &#10;                        else:&#10;                            # Objeto no meio da caixa&#10;                            status = &quot;PARCIALMENTE CHEIA&quot;&#10;                            cor_status = (0, 165, 255)  # Laranja&#10;                            texto_info = f&quot;Parcial {percentual_cheio:.0f}% | Alt: {altura_conteudo*100:.1f}cm&quot;&#10;&#10;                        # Desenhar texto com informações detalhadas&#10;                        x, y, w, h = cv2.boundingRect(melhor_retangulo)&#10;                        cv2.putText(display_image, texto_info, (x, y + h + 25),&#10;                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, cor_status, 2)&#10;                        &#10;                        # Informação adicional de debug&#10;                        texto_debug = f&quot;Medida: {distancia_mediana:.3f}m | Fundo: {ALTURA_FUNDO_CAIXA:.3f}m | Borda: {ALTURA_BORDA_CAIXA:.3f}m&quot;&#10;                        cv2.putText(display_image, texto_debug, (x, y + h + 50),&#10;                                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)&#10;&#10;            # --- EXIBIÇÃO ---&#10;            # Informações no topo da tela&#10;            cv2.rectangle(display_image, (0, 0), (640, 100), (0, 0, 0), -1)&#10;            cv2.putText(display_image, f&quot;MODO IR - {status}&quot;, (20, 40),&#10;                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, cor_status, 2)&#10;            cv2.putText(display_image, f&quot;Camera: {ALTURA_CAMERA_CHAO*100:.1f}cm | Caixa: {ALTURA_CAIXA*100:.0f}cm&quot;, &#10;                        (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)&#10;            cv2.putText(display_image, &quot;Pressione 'q' para sair&quot;, &#10;                        (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)&#10;&#10;            # Mostra a visão do sensor IR (que vê no escuro)&#10;            cv2.imshow('Monitor Deteccao Caixa', display_image)&#10;&#10;            # Opcional: ver o mapa de calor da profundidade filtrada&#10;            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)&#10;            cv2.imshow('Depth Map Filtrado', depth_colormap)&#10;&#10;            if cv2.waitKey(1) &amp; 0xFF == ord('q'):&#10;                break&#10;&#10;    finally:&#10;        pipeline.stop()&#10;        cv2.destroyAllWindows()&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    rastrear_cacamba_hostil()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/verificar_caixaV2.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/verificar_caixaV2.py" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="import pyrealsense2 as rs&#10;import numpy as np&#10;import cv2&#10;&#10;&#10;def verificar_caixa_por_altura():&#10;    &quot;&quot;&quot;&#10;    Algoritmo simplificado que verifica se a caixa está cheia ou vazia&#10;    baseado APENAS na medição de altura (distância da câmera até a superfície).&#10;&#10;    Configuração do teste:&#10;    - Caixa de isopor: 20cm de altura&#10;    - Câmera: 72.5cm do chão (posicionada acima da caixa)&#10;    &quot;&quot;&quot;&#10;&#10;    # --- CONFIGURAÇÕES ---&#10;    ALTURA_CAMERA_CHAO = 0.725  # 72.5cm em metros&#10;    ALTURA_CAIXA = 0.20  # 20cm em metros&#10;&#10;    # Distâncias de referência calculadas&#10;    DISTANCIA_FUNDO_VAZIO = ALTURA_CAMERA_CHAO  # 0.725m quando vazia (vê o fundo)&#10;    DISTANCIA_BORDA_CHEIA = ALTURA_CAMERA_CHAO - ALTURA_CAIXA  # 0.525m quando cheia até a borda&#10;&#10;    # Tolerância para flutuações na medição (3cm)&#10;    TOLERANCIA = 0.03&#10;&#10;    # Limites de detecção com tolerância&#10;    LIMITE_VAZIA = DISTANCIA_FUNDO_VAZIO - TOLERANCIA  # &gt;= 0.695m = vazia&#10;    LIMITE_CHEIA = DISTANCIA_BORDA_CHEIA + TOLERANCIA  # &lt;= 0.555m = cheia&#10;    &#10;    # Configurações para detecção automática da caixa&#10;    AREA_MINIMA_CAIXA = 3000  # Área mínima em pixels para considerar um contorno válido&#10;    TAMANHO_KERNEL_BLUR = 7  # Tamanho do kernel para suavização&#10;&#10;    # --- INICIALIZAÇÃO DA REALSENSE ---&#10;    pipeline = rs.pipeline()&#10;    config = rs.config()&#10;&#10;    # Habilitar streams de profundidade e cor&#10;    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)&#10;    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)&#10;&#10;    print(&quot;=&quot;*70)&#10;    print(&quot;SISTEMA DE DETECÇÃO DE NÍVEL DA CAIXA&quot;)&#10;    print(&quot;=&quot;*70)&#10;    print(f&quot;Altura da câmera: {ALTURA_CAMERA_CHAO*100:.1f}cm&quot;)&#10;    print(f&quot;Altura da caixa: {ALTURA_CAIXA*100:.0f}cm&quot;)&#10;    print(f&quot;Distância esperada (vazia): ~{DISTANCIA_FUNDO_VAZIO:.3f}m&quot;)&#10;    print(f&quot;Distância esperada (cheia): ~{DISTANCIA_BORDA_CHEIA:.3f}m&quot;)&#10;    print(f&quot;Limite vazia: &gt;= {LIMITE_VAZIA:.3f}m&quot;)&#10;    print(f&quot;Limite cheia: &lt;= {LIMITE_CHEIA:.3f}m&quot;)&#10;    print(&quot;=&quot;*70)&#10;    print(&quot;\nIniciando câmera RealSense...&quot;)&#10;&#10;    profile = pipeline.start(config)&#10;&#10;    # Obter escala de profundidade&#10;    depth_sensor = profile.get_device().first_depth_sensor()&#10;    depth_scale = depth_sensor.get_depth_scale()&#10;&#10;    # Alinhar frames&#10;    align = rs.align(rs.stream.color)&#10;&#10;    # Configurar filtros para melhorar precisão&#10;    spatial = rs.spatial_filter()&#10;    spatial.set_option(rs.option.filter_magnitude, 2)&#10;    spatial.set_option(rs.option.filter_smooth_alpha, 0.5)&#10;    spatial.set_option(rs.option.filter_smooth_delta, 20)&#10;&#10;    temporal = rs.temporal_filter()&#10;&#10;    print(&quot;\n✓ Câmera iniciada!&quot;)&#10;    print(&quot;\nPosicione a caixa centralizada abaixo da câmera.&quot;)&#10;    print(&quot;Pressione 'q' para sair.\n&quot;)&#10;&#10;    try:&#10;        while True:&#10;            # Capturar frames&#10;            frames = pipeline.wait_for_frames()&#10;            aligned_frames = align.process(frames)&#10;&#10;            depth_frame = aligned_frames.get_depth_frame()&#10;            color_frame = aligned_frames.get_color_frame()&#10;&#10;            if not depth_frame or not color_frame:&#10;                continue&#10;&#10;            # Aplicar filtros para reduzir ruído&#10;            filtered_depth = spatial.process(depth_frame)&#10;            filtered_depth = temporal.process(filtered_depth)&#10;&#10;            # Converter para numpy&#10;            depth_image = np.asanyarray(filtered_depth.get_data())&#10;            color_image = np.asanyarray(color_frame.get_data())&#10;&#10;            # Obter dimensões&#10;            h, w = color_image.shape[:2]&#10;            &#10;            # --- DETECÇÃO AUTOMÁTICA DA CAIXA ---&#10;            # Converter para escala de cinza para processamento&#10;            gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)&#10;            &#10;            # Aplicar blur para reduzir ruído&#10;            blurred = cv2.GaussianBlur(gray, (TAMANHO_KERNEL_BLUR, TAMANHO_KERNEL_BLUR), 0)&#10;            &#10;            # Detecção de bordas&#10;            edges = cv2.Canny(blurred, 50, 150)&#10;            &#10;            # Dilatar as bordas para conectar linhas quebradas&#10;            kernel = np.ones((3, 3), np.uint8)&#10;            edges = cv2.dilate(edges, kernel, iterations=2)&#10;            &#10;            # Encontrar contornos&#10;            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)&#10;            &#10;            # Procurar o maior retângulo (que deve ser a caixa)&#10;            melhor_contorno = None&#10;            maior_area = 0&#10;            caixa_detectada = False&#10;            &#10;            for contour in contours:&#10;                area = cv2.contourArea(contour)&#10;                if area &gt; AREA_MINIMA_CAIXA:&#10;                    # Aproximar para um polígono&#10;                    perimeter = cv2.arcLength(contour, True)&#10;                    approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)&#10;                    &#10;                    # Verificar se é um retângulo (4 vértices)&#10;                    if len(approx) &gt;= 4:&#10;                        if area &gt; maior_area:&#10;                            maior_area = area&#10;                            melhor_contorno = approx&#10;                            caixa_detectada = True&#10;            &#10;            # Se detectou a caixa, usar sua região; caso contrário, usar centro&#10;            if caixa_detectada and melhor_contorno is not None:&#10;                # Obter retângulo delimitador&#10;                x1, y1, w_box, h_box = cv2.boundingRect(melhor_contorno)&#10;                x2 = x1 + w_box&#10;                y2 = y1 + h_box&#10;                &#10;                # Extrair região de profundidade dentro da caixa&#10;                regiao_depth = depth_image[y1:y2, x1:x2]&#10;                &#10;                # Desenhar o contorno da caixa detectada&#10;                cv2.drawContours(color_image, [melhor_contorno], -1, (0, 255, 255), 3)&#10;                cv2.rectangle(color_image, (x1, y1), (x2, y2), (255, 0, 255), 2)&#10;                &#10;            else:&#10;                # Fallback: usar região central se não detectar a caixa&#10;                center_x, center_y = w // 2, h // 2&#10;                regiao_size = 50&#10;                x1 = max(0, center_x - regiao_size)&#10;                x2 = min(w, center_x + regiao_size)&#10;                y1 = max(0, center_y - regiao_size)&#10;                y2 = min(h, center_y + regiao_size)&#10;                &#10;                regiao_depth = depth_image[y1:y2, x1:x2]&#10;                &#10;                # Desenhar cruz no centro como fallback&#10;                cruz_tamanho = 30&#10;                cv2.line(color_image, (center_x - cruz_tamanho, center_y), &#10;                         (center_x + cruz_tamanho, center_y), (255, 255, 255), 2)&#10;                cv2.line(color_image, (center_x, center_y - cruz_tamanho), &#10;                         (center_x, center_y + cruz_tamanho), (255, 255, 255), 2)&#10;&#10;            # Filtrar valores válidos (&gt; 0)&#10;            regiao_valida = regiao_depth[regiao_depth &gt; 0]&#10;&#10;            # Calcular distância mediana (mais robusta que média)&#10;            if len(regiao_valida) &gt; 10 and (caixa_detectada or True):  # Garantir mínimo de pontos válidos&#10;                distancia_pixels = np.median(regiao_valida)&#10;                distancia_metros = distancia_pixels * depth_scale&#10;&#10;                # Calcular altura do conteúdo dentro da caixa&#10;                altura_conteudo = ALTURA_CAMERA_CHAO - distancia_metros&#10;                percentual_cheio = (altura_conteudo / ALTURA_CAIXA) * 100&#10;&#10;                # Limitar percentual entre 0 e 100&#10;                percentual_cheio = max(0, min(100, percentual_cheio))&#10;&#10;                # --- LÓGICA DE DECISÃO BASEADA APENAS NA ALTURA ---&#10;                if distancia_metros &gt;= LIMITE_VAZIA:&#10;                    # Distância grande = câmera vê o fundo&#10;                    status = &quot;VAZIA&quot;&#10;                    cor_status = (0, 0, 255)  # Vermelho&#10;                    cor_regiao = (0, 0, 255)&#10;&#10;                elif distancia_metros &lt;= LIMITE_CHEIA:&#10;                    # Distância pequena = objeto até a borda ou acima&#10;                    status = &quot;CHEIA&quot;&#10;                    cor_status = (0, 255, 0)  # Verde&#10;                    cor_regiao = (0, 255, 0)&#10;&#10;                else:&#10;                    # Distância intermediária = parcialmente cheia&#10;                    status = &quot;PARCIAL&quot;&#10;                    cor_status = (0, 165, 255)  # Laranja&#10;                    cor_regiao = (0, 165, 255)&#10;&#10;                # Preparar textos informativos&#10;                texto_status = f&quot;STATUS: {status}&quot;&#10;                if caixa_detectada:&#10;                    texto_distancia = f&quot;Distancia: {distancia_metros:.3f}m | CAIXA DETECTADA&quot;&#10;                else:&#10;                    texto_distancia = f&quot;Distancia: {distancia_metros:.3f}m | Modo Centro&quot;&#10;                texto_altura = f&quot;Altura conteudo: {altura_conteudo*100:.1f}cm&quot;&#10;                texto_percentual = f&quot;Preenchimento: {percentual_cheio:.0f}%&quot;&#10;                texto_area = f&quot;Area da caixa: {maior_area:.0f} px²&quot; if caixa_detectada else &quot;&quot;&#10;&#10;            else:&#10;                # Medição inválida&#10;                status = &quot;SEM LEITURA&quot;&#10;                cor_status = (128, 128, 128)&#10;                cor_regiao = (128, 128, 128)&#10;                texto_status = &quot;STATUS: SEM LEITURA&quot;&#10;                if caixa_detectada:&#10;                    texto_distancia = &quot;Caixa detectada | Aguardando medicao valida...&quot;&#10;                else:&#10;                    texto_distancia = &quot;Procurando caixa...&quot;&#10;                texto_altura = &quot;&quot;&#10;                texto_percentual = &quot;&quot;&#10;                texto_area = &quot;&quot;&#10;&#10;            # --- DESENHAR VISUALIZAÇÃO ---&#10;            &#10;            # Desenhar região de medição&#10;            cv2.rectangle(color_image, (x1, y1), (x2, y2), cor_regiao, 3)&#10;&#10;            # Painel superior com informações&#10;            cv2.rectangle(color_image, (0, 0), (w, 210), (0, 0, 0), -1)&#10;&#10;            # Status grande&#10;            cv2.putText(color_image, texto_status, (20, 50),&#10;                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, cor_status, 3)&#10;&#10;            # Informações detalhadas&#10;            y_offset = 90&#10;            cv2.putText(color_image, texto_distancia, (20, y_offset),&#10;                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)&#10;&#10;            if texto_altura:&#10;                cv2.putText(color_image, texto_altura, (20, y_offset + 30),&#10;                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)&#10;                cv2.putText(color_image, texto_percentual, (20, y_offset + 60),&#10;                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, cor_status, 2)&#10;                if texto_area:&#10;                    cv2.putText(color_image, texto_area, (20, y_offset + 90),&#10;                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 255, 255), 1)&#10;&#10;            # Rodapé com instruções&#10;            cv2.rectangle(color_image, (0, h - 40), (w, h), (0, 0, 0), -1)&#10;            cv2.putText(color_image, &quot;Pressione 'q' para sair&quot;, (20, h - 15),&#10;                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)&#10;&#10;            # Exibir informações de configuração no canto direito&#10;            info_config = [&#10;                f&quot;Camera: {ALTURA_CAMERA_CHAO*100:.0f}cm&quot;,&#10;                f&quot;Caixa: {ALTURA_CAIXA*100:.0f}cm&quot;,&#10;                f&quot;Fundo: {DISTANCIA_FUNDO_VAZIO:.3f}m&quot;,&#10;                f&quot;Borda: {DISTANCIA_BORDA_CHEIA:.3f}m&quot;&#10;            ]&#10;&#10;            for i, info in enumerate(info_config):&#10;                cv2.putText(color_image, info, (w - 200, 30 + i*25),&#10;                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (180, 180, 180), 1)&#10;&#10;            # Mostrar imagem&#10;            cv2.imshow('Detector de Nivel da Caixa', color_image)&#10;&#10;            # Criar mapa de calor da profundidade&#10;            depth_colormap = cv2.applyColorMap(&#10;                cv2.convertScaleAbs(depth_image, alpha=0.05),&#10;                cv2.COLORMAP_JET&#10;            )&#10;&#10;            # Desenhar região no mapa de calor&#10;            cv2.rectangle(depth_colormap, (x1, y1), (x2, y2), (255, 255, 255), 2)&#10;            cv2.imshow('Mapa de Profundidade', depth_colormap)&#10;&#10;            # Imprimir no console&#10;            if status != &quot;SEM LEITURA&quot;:&#10;                if 'distancia_metros' in locals() and 'altura_conteudo' in locals() and 'percentual_cheio' in locals():&#10;                    print(f&quot;\r{status:8} | Dist: {distancia_metros:.3f}m | &quot;&#10;                          f&quot;Alt: {altura_conteudo*100:5.1f}cm | {percentual_cheio:3.0f}%&quot;,&#10;                          end='', flush=True)&#10;&#10;            # Sair com 'q'&#10;            if cv2.waitKey(1) &amp; 0xFF == ord('q'):&#10;                break&#10;&#10;    finally:&#10;        print(&quot;\n\n&quot; + &quot;=&quot;*70)&#10;        print(&quot;Encerrando sistema...&quot;)&#10;        pipeline.stop()&#10;        cv2.destroyAllWindows()&#10;        print(&quot;✓ Câmera desligada. Sistema encerrado.&quot;)&#10;        print(&quot;=&quot;*70)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    verificar_caixa_por_altura()&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/verificar_caixaV3.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/verificar_caixaV3.py" />
              <option name="updatedContent" value="import pyrealsense2 as rs&#10;import numpy as np&#10;import cv2&#10;from collections import deque&#10;import time&#10;&#10;&#10;def verificar_caixa_v3():&#10;    &quot;&quot;&quot;&#10;    Versão 3: Sistema híbrido avançado com detecção por profundidade&#10;    &#10;    MELHORIAS:&#10;    - Detecção de caixa usando mapa de profundidade (não depende de iluminação)&#10;    - Filtro temporal com histórico para estabilizar detecção&#10;    - Sensor infravermelho para ambientes escuros&#10;    - Medição em múltiplas regiões para maior precisão&#10;    - Alertas visuais e sonoros (beep no terminal)&#10;    - Estatísticas em tempo real&#10;    &quot;&quot;&quot;&#10;    &#10;    # --- CONFIGURAÇÕES ---&#10;    ALTURA_CAMERA_CHAO = 0.725  # 72.5cm em metros&#10;    ALTURA_CAIXA = 0.20  # 20cm em metros&#10;    &#10;    # Distâncias de referência&#10;    DISTANCIA_FUNDO_VAZIO = ALTURA_CAMERA_CHAO  # 0.725m&#10;    DISTANCIA_BORDA_CHEIA = ALTURA_CAMERA_CHAO - ALTURA_CAIXA  # 0.525m&#10;    &#10;    # Tolerâncias&#10;    TOLERANCIA = 0.03  # 3cm&#10;    LIMITE_VAZIA = DISTANCIA_FUNDO_VAZIO - TOLERANCIA&#10;    LIMITE_CHEIA = DISTANCIA_BORDA_CHEIA + TOLERANCIA&#10;    &#10;    # Filtros de distância&#10;    CLIP_MIN = 0.3&#10;    CLIP_MAX = 1.5&#10;    &#10;    # Detecção por profundidade&#10;    PROFUNDIDADE_MIN_CAIXA = 0.45  # Objetos mais próximos que isso são considerados parte da caixa&#10;    PROFUNDIDADE_MAX_CAIXA = 0.85  # Objetos mais distantes são o fundo&#10;    AREA_MINIMA_PIXELS = 5000&#10;    &#10;    # Histórico temporal para estabilização&#10;    TAMANHO_HISTORICO = 10&#10;    historico_status = deque(maxlen=TAMANHO_HISTORICO)&#10;    historico_distancias = deque(maxlen=30)&#10;    &#10;    # Estatísticas&#10;    contador_frames = 0&#10;    tempo_inicio = time.time()&#10;    ultima_mudanca_status = None&#10;    status_anterior = None&#10;    &#10;    # --- INICIALIZAÇÃO DA REALSENSE ---&#10;    pipeline = rs.pipeline()&#10;    config = rs.config()&#10;    &#10;    # Usar IR para ambientes escuros + RGB para visualização&#10;    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)&#10;    config.enable_stream(rs.stream.infrared, 1, 640, 480, rs.format.y8, 30)&#10;    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)&#10;    &#10;    print(&quot;=&quot;*70)&#10;    print(&quot;SISTEMA DE DETECÇÃO DE NÍVEL DA CAIXA V3&quot;)&#10;    print(&quot;=&quot;*70)&#10;    print(&quot; Detecção híbrida por profundidade + IR&quot;)&#10;    print(&quot; Histórico temporal para estabilização&quot;)&#10;    print(&quot; Visualização aprimorada com estatísticas&quot;)&#10;    print(&quot;=&quot;*70)&#10;    print(f&quot;Altura câmera: {ALTURA_CAMERA_CHAO*100:.1f}cm | Altura caixa: {ALTURA_CAIXA*100:.0f}cm&quot;)&#10;    print(&quot;=&quot;*70)&#10;    &#10;    profile = pipeline.start(config)&#10;    &#10;    # Configurar sensor de profundidade&#10;    device = profile.get_device()&#10;    depth_sensor = device.first_depth_sensor()&#10;    depth_scale = depth_sensor.get_depth_scale()&#10;    &#10;    # Maximizar laser para penetrar poeira&#10;    if depth_sensor.supports(rs.option.emitter_enabled):&#10;        depth_sensor.set_option(rs.option.emitter_enabled, 1.0)&#10;        if depth_sensor.supports(rs.option.laser_power):&#10;            max_laser = depth_sensor.get_option_range(rs.option.laser_power).max&#10;            depth_sensor.set_option(rs.option.laser_power, max_laser)&#10;            print(f&quot;✓ Laser configurado: {max_laser:.0f}&quot;)&#10;    &#10;    # Filtros avançados&#10;    decimation = rs.decimation_filter()&#10;    spatial = rs.spatial_filter()&#10;    spatial.set_option(rs.option.filter_magnitude, 2)&#10;    spatial.set_option(rs.option.filter_smooth_alpha, 0.5)&#10;    spatial.set_option(rs.option.filter_smooth_delta, 20)&#10;    &#10;    temporal = rs.temporal_filter()&#10;    temporal.set_option(rs.option.filter_smooth_alpha, 0.4)&#10;    temporal.set_option(rs.option.filter_smooth_delta, 20)&#10;    &#10;    hole_filling = rs.hole_filling_filter()&#10;    &#10;    print(&quot;✓ Filtros configurados&quot;)&#10;    print(&quot;\n Sistema iniciado! Pressione 'q' para sair.\n&quot;)&#10;    &#10;    try:&#10;        while True:&#10;            contador_frames += 1&#10;            frames = pipeline.wait_for_frames()&#10;            &#10;            # Obter frames&#10;            depth_frame = frames.get_depth_frame()&#10;            ir_frame = frames.get_infrared_frame(1)&#10;            color_frame = frames.get_color_frame()&#10;            &#10;            if not depth_frame or not ir_frame:&#10;                continue&#10;            &#10;            # Aplicar filtros em cascata&#10;            filtered_depth = decimation.process(depth_frame)&#10;            filtered_depth = spatial.process(filtered_depth)&#10;            filtered_depth = temporal.process(filtered_depth)&#10;            filtered_depth = hole_filling.process(filtered_depth)&#10;            &#10;            # Converter para numpy&#10;            depth_image = np.asanyarray(filtered_depth.get_data())&#10;            ir_image = np.asanyarray(ir_frame.get_data())&#10;            &#10;            # Usar color se disponível, senão IR&#10;            if color_frame:&#10;                display_image = np.asanyarray(color_frame.get_data())&#10;            else:&#10;                display_image = cv2.cvtColor(ir_image, cv2.COLOR_GRAY2BGR)&#10;            &#10;            h, w = display_image.shape[:2]&#10;            &#10;            # --- DETECÇÃO DA CAIXA POR SEGMENTAÇÃO DE PROFUNDIDADE ---&#10;            depth_meters = depth_image * depth_scale&#10;            &#10;            # Criar máscara da região de interesse (onde pode estar a caixa)&#10;            mask_roi = (depth_meters &gt; PROFUNDIDADE_MIN_CAIXA) &amp; (depth_meters &lt; PROFUNDIDADE_MAX_CAIXA)&#10;            &#10;            # Encontrar o maior componente conectado (a caixa)&#10;            mask_uint8 = mask_roi.astype(np.uint8) * 255&#10;            &#10;            # Operações morfológicas para limpar a máscara&#10;            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))&#10;            mask_uint8 = cv2.morphologyEx(mask_uint8, cv2.MORPH_CLOSE, kernel)&#10;            mask_uint8 = cv2.morphologyEx(mask_uint8, cv2.MORPH_OPEN, kernel)&#10;            &#10;            # Encontrar contornos na máscara de profundidade&#10;            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)&#10;            &#10;            caixa_detectada = False&#10;            melhor_contorno = None&#10;            maior_area = 0&#10;            regiao_medicao = None&#10;            &#10;            for contour in contours:&#10;                area = cv2.contourArea(contour)&#10;                if area &gt; AREA_MINIMA_PIXELS:&#10;                    if area &gt; maior_area:&#10;                        maior_area = area&#10;                        melhor_contorno = contour&#10;                        caixa_detectada = True&#10;            &#10;            # --- MEDIÇÃO ---&#10;            if caixa_detectada and melhor_contorno is not None:&#10;                # Obter retângulo delimitador&#10;                x1, y1, w_box, h_box = cv2.boundingRect(melhor_contorno)&#10;                x2, y2 = x1 + w_box, y1 + h_box&#10;                &#10;                # Desenhar contorno da caixa&#10;                cv2.drawContours(display_image, [melhor_contorno], -1, (0, 255, 255), 2)&#10;                cv2.rectangle(display_image, (x1, y1), (x2, y2), (255, 0, 255), 2)&#10;                &#10;                # Dividir a região em 9 sub-regiões (grid 3x3) para medição mais robusta&#10;                regiao_depth = depth_meters[y1:y2, x1:x2]&#10;                h_reg, w_reg = regiao_depth.shape&#10;                &#10;                medicoes_grid = []&#10;                grid_size = 3&#10;                cell_h, cell_w = h_reg // grid_size, w_reg // grid_size&#10;                &#10;                for i in range(grid_size):&#10;                    for j in range(grid_size):&#10;                        y_start = i * cell_h&#10;                        y_end = (i + 1) * cell_h if i &lt; grid_size - 1 else h_reg&#10;                        x_start = j * cell_w&#10;                        x_end = (j + 1) * cell_w if j &lt; grid_size - 1 else w_reg&#10;                        &#10;                        celula = regiao_depth[y_start:y_end, x_start:x_end]&#10;                        celula_valida = celula[(celula &gt; CLIP_MIN) &amp; (celula &lt; CLIP_MAX)]&#10;                        &#10;                        if len(celula_valida) &gt; 10:&#10;                            medicoes_grid.append(np.median(celula_valida))&#10;                            &#10;                            # Desenhar mini-retângulos do grid&#10;                            cv2.rectangle(display_image, &#10;                                        (x1 + x_start, y1 + y_start), &#10;                                        (x1 + x_end, y1 + y_end), &#10;                                        (100, 100, 100), 1)&#10;                &#10;                regiao_medicao = (x1, y1, x2, y2)&#10;                &#10;            else:&#10;                # Fallback: usar região central&#10;                center_x, center_y = w // 2, h // 2&#10;                size = 50&#10;                x1 = max(0, center_x - size)&#10;                x2 = min(w, center_x + size)&#10;                y1 = max(0, center_y - size)&#10;                y2 = min(h, center_y + size)&#10;                &#10;                regiao_depth = depth_meters[y1:y2, x1:x2]&#10;                regiao_valida = regiao_depth[(regiao_depth &gt; CLIP_MIN) &amp; (regiao_depth &lt; CLIP_MAX)]&#10;                &#10;                if len(regiao_valida) &gt; 10:&#10;                    medicoes_grid = [np.median(regiao_valida)]&#10;                else:&#10;                    medicoes_grid = []&#10;                &#10;                # Desenhar cruz&#10;                cv2.line(display_image, (center_x - 30, center_y), &#10;                        (center_x + 30, center_y), (255, 255, 255), 2)&#10;                cv2.line(display_image, (center_x, center_y - 30), &#10;                        (center_x, center_y + 30), (255, 255, 255), 2)&#10;                &#10;                regiao_medicao = (x1, y1, x2, y2)&#10;            &#10;            # --- PROCESSAMENTO DE MEDIÇÕES ---&#10;            if len(medicoes_grid) &gt; 0:&#10;                # Usar mediana das medianas (super robusto!)&#10;                distancia_final = np.median(medicoes_grid)&#10;                historico_distancias.append(distancia_final)&#10;                &#10;                # Calcular estatísticas&#10;                altura_conteudo = ALTURA_CAMERA_CHAO - distancia_final&#10;                percentual_cheio = (altura_conteudo / ALTURA_CAIXA) * 100&#10;                percentual_cheio = max(0, min(100, percentual_cheio))&#10;                &#10;                # Determinar status&#10;                if distancia_final &gt;= LIMITE_VAZIA:&#10;                    status_atual = &quot;VAZIA&quot;&#10;                    cor_status = (0, 0, 255)  # Vermelho&#10;                elif distancia_final &lt;= LIMITE_CHEIA:&#10;                    status_atual = &quot;CHEIA&quot;&#10;                    cor_status = (0, 255, 0)  # Verde&#10;                else:&#10;                    status_atual = &quot;PARCIAL&quot;&#10;                    cor_status = (0, 165, 255)  # Laranja&#10;                &#10;                # Adicionar ao histórico&#10;                historico_status.append(status_atual)&#10;                &#10;                # Estabilização: status só muda se 70% do histórico concordar&#10;                if len(historico_status) &gt;= 5:&#10;                    contagem = {&#10;                        &quot;VAZIA&quot;: historico_status.count(&quot;VAZIA&quot;),&#10;                        &quot;PARCIAL&quot;: historico_status.count(&quot;PARCIAL&quot;),&#10;                        &quot;CHEIA&quot;: historico_status.count(&quot;CHEIA&quot;)&#10;                    }&#10;                    status_estavel = max(contagem, key=contagem.get)&#10;                else:&#10;                    status_estavel = status_atual&#10;                &#10;                # Detectar mudança de status&#10;                if status_estavel != status_anterior:&#10;                    ultima_mudanca_status = time.time()&#10;                    print(f&quot;\n MUDANÇA DE STATUS: {status_anterior or 'N/A'} → {status_estavel}&quot;)&#10;                    status_anterior = status_estavel&#10;                &#10;                # Calcular métricas&#10;                desvio_padrao = np.std(list(historico_distancias)) if len(historico_distancias) &gt; 1 else 0&#10;                confianca = 100 - (desvio_padrao * 1000)  # Quanto menor o desvio, maior a confiança&#10;                confianca = max(0, min(100, confianca))&#10;                &#10;                # Preparar textos&#10;                modo = &quot;CAIXA DETECTADA&quot; if caixa_detectada else &quot;Modo Centro&quot;&#10;                texto_dist = f&quot;Dist: {distancia_final:.3f}m ({len(medicoes_grid)} pts)&quot;&#10;                texto_altura = f&quot;Altura: {altura_conteudo*100:.1f}cm&quot;&#10;                texto_percent = f&quot;{percentual_cheio:.0f}%&quot;&#10;                texto_conf = f&quot;Confianca: {confianca:.0f}%&quot;&#10;                texto_area = f&quot;Area: {maior_area:.0f}px²&quot; if caixa_detectada else &quot;&quot;&#10;                &#10;            else:&#10;                status_estavel = &quot;SEM LEITURA&quot;&#10;                cor_status = (128, 128, 128)&#10;                modo = &quot;Aguardando dados...&quot;&#10;                texto_dist = &quot;Sem medicao valida&quot;&#10;                texto_altura = &quot;&quot;&#10;                texto_percent = &quot;&quot;&#10;                texto_conf = &quot;&quot;&#10;                texto_area = &quot;&quot;&#10;                confianca = 0&#10;            &#10;            # --- VISUALIZAÇÃO AVANÇADA ---&#10;            &#10;            # Painel superior (status)&#10;            cv2.rectangle(display_image, (0, 0), (w, 140), (20, 20, 20), -1)&#10;            &#10;            # Status grande com borda&#10;            status_text = f&quot;STATUS: {status_estavel}&quot;&#10;            cv2.putText(display_image, status_text, (22, 52), &#10;                       cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 5)&#10;            cv2.putText(display_image, status_text, (20, 50), &#10;                       cv2.FONT_HERSHEY_SIMPLEX, 1.3, cor_status, 3)&#10;            &#10;            # Informações detalhadas&#10;            cv2.putText(display_image, texto_dist, (20, 85), &#10;                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)&#10;            cv2.putText(display_image, modo, (20, 105), &#10;                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 255, 255), 1)&#10;            &#10;            if texto_altura:&#10;                cv2.putText(display_image, f&quot;{texto_altura} | {texto_percent}&quot;, (20, 125), &#10;                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, cor_status, 2)&#10;            &#10;            # Painel lateral direito (estatísticas)&#10;            cv2.rectangle(display_image, (w - 200, 0), (w, 180), (20, 20, 20), -1)&#10;            &#10;            stats_y = 25&#10;            cv2.putText(display_image, &quot;ESTATISTICAS&quot;, (w - 190, stats_y), &#10;                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)&#10;            &#10;            stats_y += 25&#10;            cv2.putText(display_image, texto_conf, (w - 190, stats_y), &#10;                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100, 255, 100), 1)&#10;            &#10;            stats_y += 20&#10;            fps = contador_frames / (time.time() - tempo_inicio)&#10;            cv2.putText(display_image, f&quot;FPS: {fps:.1f}&quot;, (w - 190, stats_y), &#10;                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)&#10;            &#10;            stats_y += 20&#10;            cv2.putText(display_image, f&quot;Frames: {contador_frames}&quot;, (w - 190, stats_y), &#10;                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)&#10;            &#10;            if texto_area:&#10;                stats_y += 20&#10;                cv2.putText(display_image, texto_area, (w - 190, stats_y), &#10;                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)&#10;            &#10;            stats_y += 25&#10;            cv2.putText(display_image, f&quot;Historico: {len(historico_status)}/{TAMANHO_HISTORICO}&quot;, &#10;                       (w - 190, stats_y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)&#10;            &#10;            # Desenhar região de medição&#10;            if regiao_medicao:&#10;                x1, y1, x2, y2 = regiao_medicao&#10;                cv2.rectangle(display_image, (x1, y1), (x2, y2), cor_status, 3)&#10;            &#10;            # Barra de confiança&#10;            barra_x = w - 190&#10;            barra_y = 155&#10;            barra_w = 180&#10;            barra_h = 15&#10;            &#10;            cv2.rectangle(display_image, (barra_x, barra_y), (barra_x + barra_w, barra_y + barra_h), &#10;                         (60, 60, 60), -1)&#10;            &#10;            if confianca &gt; 0:&#10;                barra_preenchida = int((confianca / 100) * barra_w)&#10;                cor_barra = (0, 255, 0) if confianca &gt; 70 else (0, 165, 255) if confianca &gt; 40 else (0, 0, 255)&#10;                cv2.rectangle(display_image, (barra_x, barra_y), &#10;                             (barra_x + barra_preenchida, barra_y + barra_h), cor_barra, -1)&#10;            &#10;            # Rodapé&#10;            cv2.rectangle(display_image, (0, h - 30), (w, h), (20, 20, 20), -1)&#10;            cv2.putText(display_image, &quot;Pressione 'q' para sair | V3 - Deteccao Hibrida&quot;, &#10;                       (20, h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)&#10;            &#10;            # Mostrar janela principal&#10;            cv2.imshow('Sistema de Deteccao V3', display_image)&#10;            &#10;            # Mapa de profundidade colorido&#10;            depth_colormap = cv2.applyColorMap(&#10;                cv2.convertScaleAbs(depth_image, alpha=0.05), &#10;                cv2.COLORMAP_JET&#10;            )&#10;            &#10;            # Sobrepor máscara da caixa detectada&#10;            if caixa_detectada:&#10;                overlay = depth_colormap.copy()&#10;                cv2.drawContours(overlay, [melhor_contorno], -1, (255, 255, 255), 3)&#10;                depth_colormap = cv2.addWeighted(depth_colormap, 0.7, overlay, 0.3, 0)&#10;            &#10;            cv2.imshow('Mapa de Profundidade - V3', depth_colormap)&#10;            &#10;            # Visualização IR (visão noturna)&#10;            ir_display = cv2.cvtColor(ir_image, cv2.COLOR_GRAY2BGR)&#10;            cv2.putText(ir_display, &quot;VISAO IR (Funciona no Escuro)&quot;, (10, 30), &#10;                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)&#10;            cv2.imshow('Visao Infravermelho', ir_display)&#10;            &#10;            # Sair com 'q'&#10;            if cv2.waitKey(1) &amp; 0xFF == ord('q'):&#10;                break&#10;    &#10;    finally:&#10;        tempo_total = time.time() - tempo_inicio&#10;        fps_medio = contador_frames / tempo_total&#10;        &#10;        print(&quot;\n&quot; + &quot;=&quot;*70)&#10;        print(&quot; ESTATÍSTICAS FINAIS&quot;)&#10;        print(&quot;=&quot;*70)&#10;        print(f&quot;⏱️  Tempo total: {tempo_total:.1f}s&quot;)&#10;        print(f&quot;️  Frames processados: {contador_frames}&quot;)&#10;        print(f&quot;⚡ FPS médio: {fps_medio:.1f}&quot;)&#10;        print(f&quot; Status final: {status_anterior or 'N/A'}&quot;)&#10;        print(&quot;=&quot;*70)&#10;        print(&quot;✓ Sistema encerrado com sucesso!&quot;)&#10;        &#10;        pipeline.stop()&#10;        cv2.destroyAllWindows()&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    verificar_caixa_v3()&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>